{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Github Links\n",
    "Backend: https://github.com/Rashmikoparde/Semantic-Blog-Search-Backend\n",
    "Frontend: https://github.com/Rashmikoparde/Semantic-Search-UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import codecs\n",
    "import pandas as pd\n",
    "import requests, zipfile, io\n",
    "from nltk.corpus import stopwords\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from langdetect import detect, detect_langs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The xml files are parsed and the posts from each blogs are collected and saved into csv\n",
    "#Also posts in different language other than english are ignored\n",
    "\n",
    "def process_data_long_text(folder_path):\n",
    "    print('Processing XML files from the specified folder...')\n",
    "    # Empty DataFrame\n",
    "    df = pd.DataFrame(columns=['id','label', 'text', 'gender', 'age', 'zodiac'])\n",
    "\n",
    "    \n",
    "    for i, f in enumerate(os.listdir(folder_path)[5000:10000]):\n",
    "        ds_id=f.split('.')[0].lower()\n",
    "       # print(ds_id)\n",
    "        ds_gender = f.split('.')[1].lower()\n",
    "        ds_age = f.split('.')[2]\n",
    "        ds_label = f.split('.')[3].lower()\n",
    "        ds_zodiac = f.split('.')[4].lower()\n",
    "\n",
    "        blog_file = BeautifulSoup(codecs.open(folder_path + '/' + f, encoding='utf-8', errors='ignore'), \"lxml\") \n",
    "        pk = ''\n",
    "\n",
    "        \n",
    "        for post in blog_file.find_all('post'):\n",
    "            try:\n",
    "                if detect(post.text) == 'en' : #Checks language of the post\n",
    "                    pk = pk + post.text.strip()\n",
    "            except Exception as e:\n",
    "                    pass\n",
    "                \n",
    "        post_text = pk # Converts the list back to string.\n",
    "        df = df.append({'id':ds_id,'label': ds_label, 'text': post_text, 'gender': ds_gender, 'age': ds_age, 'zodiac': ds_zodiac},ignore_index=True)\n",
    "        if(i % 200 == 0):\n",
    "           # print(i, 'completed')\n",
    "            df.to_csv('blogdata_entire_data_new.csv')\n",
    "    # Save DataFrame\n",
    "    df.to_csv('blogdata_entire_data.csv')\n",
    "    return \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    # Folder containing The Blog Authorship Corpus\n",
    "    folder_path = 'D:\\\\MastersDKE\\\\Interviews\\\\blogs'\n",
    "\n",
    "    # process_data_short_text(folder_path)\n",
    "    process_data_long_text(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>zodiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000331</td>\n",
       "      <td>indunk</td>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1000866</td>\n",
       "      <td>student</td>\n",
       "      <td>Yeah, sorry for not writing for a whole there,...</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>libra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1004904</td>\n",
       "      <td>arts</td>\n",
       "      <td>cupid,please hear my cry, cupid, please let yo...</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>capricorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1005076</td>\n",
       "      <td>arts</td>\n",
       "      <td>and did i mention that i no longer have to dea...</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1005545</td>\n",
       "      <td>engineering</td>\n",
       "      <td>B-Logs: The Business Blogs Paradox    urlLink ...</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>sagittarius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0       id        label  \\\n",
       "0           0  1000331       indunk   \n",
       "1           1  1000866      student   \n",
       "2           2  1004904         arts   \n",
       "3           3  1005076         arts   \n",
       "4           4  1005545  engineering   \n",
       "\n",
       "                                                text  gender  age       zodiac  \n",
       "0  Well, everyone got up and going this morning. ...  female   37          leo  \n",
       "1  Yeah, sorry for not writing for a whole there,...  female   17        libra  \n",
       "2  cupid,please hear my cry, cupid, please let yo...    male   23    capricorn  \n",
       "3  and did i mention that i no longer have to dea...  female   25       cancer  \n",
       "4  B-Logs: The Business Blogs Paradox    urlLink ...    male   25  sagittarius  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importing csv file to dataframe\n",
    "import pandas as pd\n",
    "\n",
    "data=pd.read_csv('blogdata_entire_data.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1401, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping Duplicate ids if any\n",
    "df=data\n",
    "df.drop_duplicates(['id'], inplace=True)\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1401, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Dropping null values from dataframe\n",
    "df.dropna(inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>zodiac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000331</td>\n",
       "      <td>indunk</td>\n",
       "      <td>Well, everyone got up and going this morning. ...</td>\n",
       "      <td>female</td>\n",
       "      <td>37</td>\n",
       "      <td>leo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000866</td>\n",
       "      <td>student</td>\n",
       "      <td>Yeah, sorry for not writing for a whole there,...</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>libra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1004904</td>\n",
       "      <td>arts</td>\n",
       "      <td>cupid,please hear my cry, cupid, please let yo...</td>\n",
       "      <td>male</td>\n",
       "      <td>23</td>\n",
       "      <td>capricorn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1005076</td>\n",
       "      <td>arts</td>\n",
       "      <td>and did i mention that i no longer have to dea...</td>\n",
       "      <td>female</td>\n",
       "      <td>25</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1005545</td>\n",
       "      <td>engineering</td>\n",
       "      <td>B-Logs: The Business Blogs Paradox    urlLink ...</td>\n",
       "      <td>male</td>\n",
       "      <td>25</td>\n",
       "      <td>sagittarius</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        label                                               text  \\\n",
       "0  1000331       indunk  Well, everyone got up and going this morning. ...   \n",
       "1  1000866      student  Yeah, sorry for not writing for a whole there,...   \n",
       "2  1004904         arts  cupid,please hear my cry, cupid, please let yo...   \n",
       "3  1005076         arts  and did i mention that i no longer have to dea...   \n",
       "4  1005545  engineering  B-Logs: The Business Blogs Paradox    urlLink ...   \n",
       "\n",
       "   gender  age       zodiac  \n",
       "0  female   37          leo  \n",
       "1  female   17        libra  \n",
       "2    male   23    capricorn  \n",
       "3  female   25       cancer  \n",
       "4    male   25  sagittarius  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drooping the column Unnamed: 0 as it is not useful\n",
    "df= df.drop([\"Unnamed: 0\"], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing the blog post and ids to list for further training\n",
    "text_list = list(df['text'])\n",
    "id_list = list(df['id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "import pickle as pkl\n",
    "import torch\n",
    "\n",
    "#creatng a model using BERT pretrained model to embedd the text into given vectors\n",
    "embedder_model = SentenceTransformer('distilbert-base-nli-stsb-mean-tokens')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Tried removing stopwords and special characters, but it did not help in improving similarity score.\n",
    "import pickle as pkl\n",
    "from spacy.lang.en import English # updated\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "corpus = text_list\n",
    "prep_text_list=[]\n",
    "stop_words = set(stopwords.words('english'))\n",
    "i=0\n",
    "for post_text in text_list:\n",
    "      #  post_text =  re.sub('[^a-zA-z0-9\\s]','',post_text).strip()\n",
    "       # post_text = [word for word in post_text if word not in stop_words]\n",
    "        #post_text = ' '.join(post_text) \n",
    "        prep_text_list.append(post_text)\n",
    "        #i+=1\n",
    "        #print(i)#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d4cb3119efb41af93d141dd96fc2717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batches', max=44, style=ProgressStyle(description_width='init…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Encoding Completed\n"
     ]
    }
   ],
   "source": [
    "#Using above model to convert text into vector format\n",
    "corpus_embeddings =  embedder_model.encode(prep_text_list,show_progress_bar=True)\n",
    "print(\"Encoding Completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the vectors to pkl file\n",
    "with open('CorpusEmbeddings2.pkl','wb') as f:\n",
    "     pkl.dump(corpus_embeddings, f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15939265269a4c8fba9afe8e8ec18d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Batches', max=1, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(1, 768)\n",
      "\n",
      "Top  most similar blogs in corpus:\n",
      "==========================Query==============================\n",
      "=== As a first step, schools and other educational institutions are to reopen from March 8th. \"The children can sit face to face with their teachers,\" says Johnson. The regions of Scotland and Wales , on the other hand, are relying on the gradual opening of schools, which began this week.  =====\n",
      "=========================================================\n",
      "Score:    0.5733158547228907 \n",
      "\n",
      "Paragraph:    Dag nab it. Look what I found               Kindergarten classes are provided for all children of kindergarten age in the Rochester School District. Michigan Statutes stipulate that before a child can enroll in kindergarten, he or she must be five (5) years old on or before December 1.       Each spring the district conducts a Kindergarten Registration to identify and enroll youngsters who will enter kindergarten in the fall. Informational evening meetings are held in the spring for parents. Newspapers will announce the dates.       It greatly assists the district’s planning efforts if all kindergarten students are identified in early spring. Parents should contact the Student Enrollment Office or plan to attend Kindergarten Registration if they have a child who meets the age requirements.   Pupils are assigned to either morning or afternoon sessions based upon geographical location. Sessions are three hours and five minutes. Daily attendance is stressed because kindergarten is an integral part of the total instructional program.\"       *grmbl* Leslie could have started last year if she were in Michigan. She was ready. We fought them in Kansas to let her to no avail. AND she's been in half a day preschool for 2 and a half years. I want to go back to work and only having half a day school for her complicates things substantially.Over off Livernois (What's the street, Deb?)   <>Rent $1275 (with $1275 deposit)  3 bed, 1 bath, 1200 sq feet + carpeted (unfinished) basement   2 bedrooms on main floor  1 on second floor  fenced yard  hard wood floors  fireplace  ceiling fans  Kitchen/dining combo  All appliances  gravel road   walk to elementary school  <>   Does it have Washer/Dryer hookups?Call the school system and get a definate start date for school in case there is anyway we can be there in time.   Done. Official first day is a half-day, August 24.        Sort videos so I can take hand-me-downs to Daniel     Find that box with Buzz/Woody stuff     Get the TV/VCR thingy back from Desiree     Pick up that travel activity book (Friday)We needed someplace to put all this info we are collecting that Jason can get to from work, I can get to from home..even Debi and Mitz can post stuff if they so desire. :)    Voila. A Moving Blog....    SO.  Here's what we have so far:  We want to move back to Rochester ASAP. Jason has his Michigan nursing lisense (Hooray) and is in the process of contacting hospitals to set up interviews there on Aug 2-4 (Mon - Wed).   We are leaving here around 5 pm on Friday, July 30 and will drive like crazy people with a goal of arriving at Debi's late Saturday night.    I understand that VBS is Aug 1-5 so Debi's gonna get the kids signed up for that. \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:111: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = op(self.values, np.asarray(other))\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2896\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2897\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-7f51374283fd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Score:   \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Paragraph:   \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[0mrow_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m==\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"paper_id:  \"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mrow_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"paper_id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1422\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1423\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1424\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1426\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1848\u001b[0m         \u001b[1;31m# fall thru to straight lookup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1849\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_key\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1850\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_get_label\u001b[1;34m(self, label, axis)\u001b[0m\n\u001b[0;32m    158\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mIndexingError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"no slices here, handle elsewhere\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 160\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_xs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    161\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mxs\u001b[1;34m(self, key, axis, level, drop_level)\u001b[0m\n\u001b[0;32m   3735\u001b[0m             \u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnew_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdrop_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdrop_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3736\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3737\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   2897\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2898\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2899\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2900\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mindexer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.index.Int64Engine._check_type\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: False"
     ]
    }
   ],
   "source": [
    "#Embedding the given query using above embedder model \n",
    "queries = ['As a first step, schools and other educational institutions are to reopen from March 8th. \"The children can sit face to face with their teachers,\" says Johnson. The regions of Scotland and Wales , on the other hand, are relying on the gradual opening of schools, which began this week. ']\n",
    "query_embeddings = embedder_model.encode(queries,show_progress_bar=True)\n",
    "print(query_embeddings.shape)\n",
    "\n",
    "# Find the closest 3 sentences of the corpus for each query sentence based on cosine similarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "closest_n = 3\n",
    "print(\"\\nTop  most similar blogs in corpus:\")\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    \n",
    "\n",
    "    \n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings,\"cosine\")[0]\n",
    "    \n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    \n",
    "    print(\"==========================Query==============================\")\n",
    "    print(\"===\",query,\"=====\")\n",
    "    print(\"=========================================================\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(\"Score:   \", (1-distance) , \"\\n\" )\n",
    "        print(\"Paragraph:   \", corpus[idx].strip(), \"\\n\" )\n",
    "        row_dict = df.loc[df.index== corpus[idx]].to_dict()\n",
    "        \n",
    "        print(\"paper_id:  \" , row_dict[\"paper_id\"][corpus[idx]], \"\\n\")\n",
    "        print(\"Label:  \" , row_dict[\"label\"][corpus[idx]] , \"\\n\")\n",
    "        print(\"Gender:  \" , row_dict[\"gender\"][corpus[idx]] , \"\\n\")\n",
    "        print(\"Age:  \" , row_dict[\"age\"][corpus[idx]] , \"\\n\")\n",
    "        print(\"-------------------------------------------\")\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpretability of the model\n",
    "- We can say that the results with high similarity score are relevant and similar to the given query.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
